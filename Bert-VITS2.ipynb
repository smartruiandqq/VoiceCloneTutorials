{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查gpu状态\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 0 连接 Google Drive\n",
    "#@markdown #STEP 0\n",
    "#@markdown ##連接 Google Drive\n",
    "#@markdown ##Connect Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 1 複製儲存庫並安裝必要的函式庫\n",
    "#@markdown #STEP 1\n",
    "#@markdown ##複製儲存庫並安裝必要的函式庫\n",
    "#@markdown ##Clone repository & Install requirements lib\n",
    "#@markdown ###\n",
    "#@markdown ###選擇訓練版本\n",
    "training_mode = \"一般版本\" # @param [\"一般版本\", \"中文特化版\"]\n",
    "training_modes = [\"一般版本\", \"中文特化版\"]\n",
    "if training_mode == training_modes[0]:\n",
    "    !git clone https://github.com/fishaudio/Bert-VITS2.git\n",
    "elif training_mode == training_modes[1]:\n",
    "    !git clone https://github.com/fishaudio/Bert-VITS2.git --branch Extra-Fix\n",
    "%cd ./Bert-VITS2/\n",
    "!pip install -r requirements.txt\n",
    "!pip install pyyaml\n",
    "\n",
    "#下載 Bert 以及 wavlm 模型\n",
    "!wget https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin?download=true -O slm/wavlm-base-plus/pytorch_model.bin\n",
    "\n",
    "if training_mode == training_modes[0]:\n",
    "    !rm -rf bert/chinese-roberta-wwm-ext-large\n",
    "    !git clone https://huggingface.co/hfl/chinese-roberta-wwm-ext-large bert/chinese-roberta-wwm-ext-large\n",
    "    !rm -rf bert/deberta-v2-large-japanese-char-wwm\n",
    "    !git clone https://huggingface.co/ku-nlp/deberta-v2-large-japanese-char-wwm bert/deberta-v2-large-japanese-char-wwm\n",
    "    !rm -rf bert/deberta-v3-large\n",
    "    !git clone https://huggingface.co/microsoft/deberta-v3-large bert/deberta-v3-large\n",
    "\n",
    "elif training_mode == training_modes[1]:\n",
    "    !rm -rf bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
    "    !git clone https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
    "    !rm -rf emotional/clap-htsat-fused\n",
    "    !git clone https://huggingface.co/laion/clap-htsat-fused emotional/clap-htsat-fused\n",
    "    !rm -rf emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
    "    !git clone https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
    "    !wget https://huggingface.co/ADT109119/G2PWModel-v2-onnx/resolve/main/g2pw.onnx?download=true -O g2pW/g2pW.onnx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-VITS2 数据预处理\n",
    "\n",
    "数据准备：\n",
    "将数据放置在 data 文件夹下，按照如下结构组织：\n",
    "\n",
    "```\n",
    "├── data\n",
    "│   ├── {你的数据集名称}\n",
    "│   │   ├── esd.list\n",
    "│   │   ├── raw\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ...\n",
    "```\n",
    "\n",
    "其中，`raw` 文件夹下保存所有的音频文件，`esd.list` 文件为标签文本，格式为\n",
    "\n",
    "```\n",
    "****.wav|{说话人名}|{语言 ID}|{标签文本}\\n\n",
    "```\n",
    "\n",
    "例如：\n",
    "```\n",
    "vo_ABDLQ001_1_paimon_02.wav|派蒙|ZH|没什么没什么，只是平时他总是站在这里，有点奇怪而已\n",
    "noa_501_0001.wav|NOA|JP|そうだね、油断しないのはとても大事なことだと思う\\n\"\n",
    "Albedo_vo_ABDLQ002_4_albedo_01.wav|Albedo|EN|Who are you? Why did you alarm them?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2-1 生成上傳按鈕載入資料集\n",
    "#@markdown #STEP 2-1\n",
    "#@markdown ##生成上傳按鈕載入資料集\n",
    "#@markdown ##Upload Dataset\n",
    "\n",
    "from google.colab import files\n",
    "import shutil\n",
    "import os\n",
    "uploaded = files.upload()\n",
    "basepath = os.getcwd()\n",
    "upload_path = \"./\"\n",
    "for filename in uploaded.keys():\n",
    "  shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, \"data.zip\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2-2 從Google Drive載入資料集\n",
    "#@markdown #STEP 2-2\n",
    "#@markdown ##載入資料集\n",
    "#@markdown ##Upload Dataset from Google Drive\n",
    "\n",
    "#@markdown ###資料集路徑\n",
    "data_set_zip_file = \"/content/drive/MyDrive/Bert-VITS2/data.zip\" #@param {type:\"string\"}\n",
    "\n",
    "!cp -rf {data_set_zip_file} ./data.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2-3 上傳音檔 透過Whisper生成字幕再自動切分 (因準確度關係 不建議使用)\n",
    "#@markdown #STEP 2-3\n",
    "#@markdown ##透過Whisper生成字幕再自動切分\n",
    "#@markdown ##(因準確度關係 不建議使用)\n",
    "#@markdown ##Upload audios and generate subtitle by OpenAI Whisper to split audios\n",
    "#@markdown ##(Not recomand)\n",
    "#@markdown ##音檔請依照 `{說話者名稱}_{語言}_{隨便的編號}` 格式\n",
    "\n",
    "!apt install ffmpeg\n",
    "\n",
    "!git clone https://github.com/ADT109119/Bert-VITS2-colab.git upload_audios\n",
    "\n",
    "!mkdir upload_audios\n",
    "!mkdir upload_audios/audio\n",
    "!mkdir upload_audios/srt\n",
    "\n",
    "upload_from_google_drive = True # @param {type:\"boolean\"}\n",
    "\n",
    "if upload_from_google_drive:\n",
    "  data_folder_path = \"/content/drive/MyDrive/Bert-VITS2/audio\" #@param {type:\"string\"}\n",
    "  !cp -rf {data_folder_path}/* ./upload_audios/audio\n",
    "else:\n",
    "  from google.colab import files\n",
    "  import shutil\n",
    "  import os\n",
    "  uploaded = files.upload()\n",
    "  basepath = os.getcwd()\n",
    "  upload_path = \"./upload_audios/audio\"\n",
    "  for filename in uploaded.keys():\n",
    "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, filename))\n",
    "\n",
    "!pip install openai-whisper\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob(\"upload_audios/audio/*.wav\")\n",
    "for path in file_list:\n",
    "  !whisper {path} --model large-v3 --output_dir \"./upload_audios/srt\"\n",
    "\n",
    "!python ./upload_audios/processing.py\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder_with_file(folder_path, file_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w') as zip_file:\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                file_path_in_folder = os.path.join(foldername, filename)\n",
    "                zip_file.write(file_path_in_folder, os.path.relpath(file_path_in_folder, os.path.dirname(folder_path)))\n",
    "\n",
    "        zip_file.write(file_path, os.path.basename(file_path))\n",
    "\n",
    "zip_folder_with_file('./upload_audios/raw', './upload_audios/esd.list', './data.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2.1 解壓縮資料集\n",
    "#@markdown #STEP 2.1\n",
    "#@markdown ##解壓縮資料集\n",
    "#@markdown ##Unzip Data\n",
    "\n",
    "#@markdown ###資料集名稱\n",
    "!mkdir data\n",
    "\n",
    "data_dir = \"dataset\" #@param {type:\"string\"}\n",
    "!unzip ./data.zip -d ./data/{data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2.5 處理資料\n",
    "#@markdown #STEP 2.5\n",
    "#@markdown ##處理資料\n",
    "#@markdown ##Process Data\n",
    "from webui_preprocess import generate_config, resample, preprocess_text, bert_gen\n",
    "batch_size = 8 # @param {type:\"integer\"}\n",
    "print(generate_config(data_dir, batch_size))\n",
    "print(resample(data_dir))\n",
    "print(preprocess_text(data_dir))\n",
    "\n",
    "#修改 config.yml\n",
    "import yaml\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data\n",
    "def save_yaml(data, file_path):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)\n",
    "# 載入 YAML 檔案\n",
    "yaml_file_path = 'config.yml'\n",
    "yaml_data = load_yaml(yaml_file_path)\n",
    "# 修改 YAML 中的內容\n",
    "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
    "yaml_data['train_ms']['config_path'] = \"configs/config.json\"\n",
    "if training_mode == training_modes[1]:\n",
    "    yaml_data['bert_gen']['num_processes'] = 1\n",
    "\n",
    "# 儲存修改後的 YAML 檔案\n",
    "save_yaml(yaml_data, yaml_file_path)\n",
    "print(bert_gen(data_dir))\n",
    "\n",
    "if training_mode == training_modes[1]:\n",
    "    !python clap_gen.py --config data/{data_dir}/configs/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2.6 自動儲存步數修改\n",
    "#@markdown #STEP 2.6\n",
    "#@markdown ##自動儲存步數修改\n",
    "\n",
    "#@markdown ###每隔n步自動儲存\n",
    "save_step = 200 # @param {type:\"integer\"}\n",
    "\n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "# 載入 JSON 檔案\n",
    "json_file_path = f\"data/{data_dir}/configs/config.json\"\n",
    "json_data = load_json(json_file_path)\n",
    "\n",
    "# 修改 JSON 中的內容\n",
    "json_data['train']['log_interval'] = save_step\n",
    "json_data['train']['eval_interval'] = save_step\n",
    "\n",
    "# 儲存修改後的 JSON 檔案\n",
    "save_json(json_data, json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 載入模型\n",
    "## 3-1、3-2 則一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 3-1 下載預訓練模型\n",
    "if training_mode == training_modes[0]:\n",
    "    !git clone https://huggingface.co/OedoSoldier/Bert-VITS2-2.3 data/{data_dir}/models\n",
    "elif training_mode == training_modes[1]:\n",
    "    !git clone https://huggingface.co/v3ucn/Bert-vits2-Extra-Pretrained_models data/{data_dir}/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 3-2 載入上次訓練到一半 儲存在 Google Drive 的模型\n",
    "!cp -f ../drive/MyDrive/Bert-VITS2/models/* data/{data_dir}/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 4 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n",
    "%reload_ext tensorboard\n",
    "model_dir = f\"./data/{data_dir}/models\"\n",
    "%tensorboard --logdir $model_dir\n",
    "\n",
    "!torchrun --nproc_per_node=1 train_ms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 5 开始推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 5 推理測試\n",
    "#@markdown #STEP 5\n",
    "#@markdown ##推理測試\n",
    "\n",
    "#@markdown ###\n",
    "#@markdown ###推理所使用的模型步數\n",
    "model_step = 2000 # @param {type:\"integer\"}\n",
    "import yaml\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data\n",
    "def save_yaml(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)\n",
    "# 載入 YAML 檔案\n",
    "yaml_file_path = 'config.yml'\n",
    "yaml_data = load_yaml(yaml_file_path)\n",
    "# 修改 YAML 中的內容\n",
    "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
    "yaml_data['webui']['share'] = \"true\"\n",
    "yaml_data['webui']['model'] = f\"models/G_{model_step}.pth\"\n",
    "yaml_data['webui']['config_path'] = \"configs/config.json\"\n",
    "# 儲存修改後的 YAML 檔案\n",
    "save_yaml(yaml_data, yaml_file_path)\n",
    "!torchrun --nproc_per_node=1 webui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 6 保存到Google Drive(自選)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 6.2 複製檔案到Google Drive\n",
    "#@markdown ###模型儲存路徑\n",
    "Google_Drive_Folder = \"/content/drive/MyDrive/Bert-VITS2\" #@param {type:\"string\"}\n",
    "#@markdown ###儲存模型步數\n",
    "steps = 2000 # @param {type:\"integer\"}\n",
    "!mkdir {Google_Drive_Folder}/models\n",
    "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/G_{steps}.pth {Google_Drive_Folder}/models/\n",
    "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/D_{steps}.pth {Google_Drive_Folder}/models/\n",
    "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/WD_{steps}.pth {Google_Drive_Folder}/models/\n",
    "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/DUR_{steps}.pth {Google_Drive_Folder}/models/\n",
    "!cp -rf /content/Bert-VITS2/data/{data_dir}/configs {Google_Drive_Folder}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 7 下載模型(自選)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ###下載模型步數\n",
    "from google.colab import files\n",
    "steps = 2000 # @param {type:\"integer\"}\n",
    "files.download(f\"./data/{data_dir}/models/G_{steps}.pth\")\n",
    "files.download(f\"./data/{data_dir}/models/D_{steps}.pth\")\n",
    "files.download(f\"./data/{data_dir}/models/WD_{steps}.pth\")\n",
    "files.download(f\"./data/{data_dir}/models/DUR_{steps}.pth\")\n",
    "files.download(f\"./data/{data_dir}/configs/config.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
