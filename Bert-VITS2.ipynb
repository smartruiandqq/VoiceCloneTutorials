{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查gpu状态\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 0 连接 Google Drive\n",
    "#@markdown #STEP 0\n",
    "#@markdown ##连接 Google Drive\n",
    "#@markdown ##Connect Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 1 复制储存库并安裝必要的函式庫\n",
    "#@markdown #STEP 1\n",
    "#@markdown ##复制储存库并安裝必要的函式庫\n",
    "#@markdown ##Clone repository & Install requirements lib\n",
    "#@markdown ###\n",
    "#@markdown ###选择训练版本\n",
    "training_mode = \"一般版本\" # @param [\"一般版本\", \"中文特化版\"]\n",
    "training_modes = [\"一般版本\", \"中文特化版\"]\n",
    "if training_mode == training_modes[0]:\n",
    "    !git clone https://github.com/fishaudio/Bert-VITS2.git\n",
    "elif training_mode == training_modes[1]:\n",
    "    !git clone https://github.com/fishaudio/Bert-VITS2.git --branch Extra-Fix\n",
    "%cd ./Bert-VITS2/\n",
    "!pip install -r requirements.txt\n",
    "!pip install pyyaml\n",
    "\n",
    "#下載 Bert 以及 wavlm 模型\n",
    "!wget https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin?download=true -O slm/wavlm-base-plus/pytorch_model.bin\n",
    "\n",
    "if training_mode == training_modes[0]:\n",
    "    !rm -rf bert/chinese-roberta-wwm-ext-large\n",
    "    !git clone https://huggingface.co/hfl/chinese-roberta-wwm-ext-large bert/chinese-roberta-wwm-ext-large\n",
    "    !rm -rf bert/deberta-v2-large-japanese-char-wwm\n",
    "    !git clone https://huggingface.co/ku-nlp/deberta-v2-large-japanese-char-wwm bert/deberta-v2-large-japanese-char-wwm\n",
    "    !rm -rf bert/deberta-v3-large\n",
    "    !git clone https://huggingface.co/microsoft/deberta-v3-large bert/deberta-v3-large\n",
    "\n",
    "elif training_mode == training_modes[1]:\n",
    "    !rm -rf bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
    "    !git clone https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
    "    !rm -rf emotional/clap-htsat-fused\n",
    "    !git clone https://huggingface.co/laion/clap-htsat-fused emotional/clap-htsat-fused\n",
    "    !rm -rf emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
    "    !git clone https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
    "    !wget https://huggingface.co/ADT109119/G2PWModel-v2-onnx/resolve/main/g2pw.onnx?download=true -O g2pW/g2pW.onnx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上传数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip  /content/Bert-VITS2/data/lcc/lcc.zip  -d   /content/Bert-VITS2/data/lcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-VITS2 数据预处理\n",
    "\n",
    "数据准备：\n",
    "将数据放置在 data 文件夹下，按照如下结构组织：\n",
    "\n",
    "```\n",
    "├── data\n",
    "│   ├── {你的数据集名称}\n",
    "│   │   ├── esd.list\n",
    "│   │   ├── raw\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ...\n",
    "```\n",
    "\n",
    "其中，`raw` 文件夹下保存所有的音频文件，`esd.list` 文件为标签文本，格式为\n",
    "\n",
    "```\n",
    "****.wav|{说话人名}|{语言 ID}|{标签文本}\\n\n",
    "```\n",
    "\n",
    "例如：\n",
    "```\n",
    "vo_ABDLQ001_1_paimon_02.wav|派蒙|ZH|没什么没什么，只是平时他总是站在这里，有点奇怪而已\n",
    "noa_501_0001.wav|NOA|JP|そうだね、油断しないのはとても大事なことだと思う\\n\"\n",
    "Albedo_vo_ABDLQ002_4_albedo_01.wav|Albedo|EN|Who are you? Why did you alarm them?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2.5 处理资料\n",
    "#@markdown #STEP 2.5\n",
    "#@markdown ##处理资料\n",
    "#@markdown ##Process Data\n",
    "from webui_preprocess import generate_config, resample, preprocess_text, bert_gen\n",
    "batch_size = 8 # @param {type:\"integer\"}\n",
    "data_dir = \"lcc\"  #@param {type:\"string\"}\n",
    "print(generate_config(data_dir, batch_size))\n",
    "print(resample(data_dir))\n",
    "print(preprocess_text(data_dir))\n",
    "\n",
    "#修改 config.yml\n",
    "import yaml\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data\n",
    "def save_yaml(data, file_path):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)\n",
    "# 載入 YAML 檔案\n",
    "yaml_file_path = 'config.yml'\n",
    "yaml_data = load_yaml(yaml_file_path)\n",
    "# 修改 YAML 中的內容\n",
    "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
    "yaml_data['train_ms']['config_path'] = \"configs/config.json\"\n",
    "if training_mode == training_modes[1]:\n",
    "    yaml_data['bert_gen']['num_processes'] = 1\n",
    "\n",
    "# 儲存修改後的 YAML 檔案\n",
    "save_yaml(yaml_data, yaml_file_path)\n",
    "print(bert_gen(data_dir))\n",
    "\n",
    "if training_mode == training_modes[1]:\n",
    "    !python clap_gen.py --config data/{data_dir}/configs/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 2.6 自動儲存步數修改\n",
    "#@markdown #STEP 2.6\n",
    "#@markdown ##自動儲存步數修改\n",
    "\n",
    "#@markdown ###每隔n步自動儲存\n",
    "save_step = 200 # @param {type:\"integer\"}\n",
    "\n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "# 載入 JSON 檔案\n",
    "json_file_path = f\"data/{data_dir}/configs/config.json\"\n",
    "json_data = load_json(json_file_path)\n",
    "\n",
    "# 修改 JSON 中的內容\n",
    "json_data['train']['log_interval'] = save_step\n",
    "json_data['train']['eval_interval'] = save_step\n",
    "\n",
    "# 儲存修改後的 JSON 檔案\n",
    "save_json(json_data, json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 载入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型\n",
    "## 3-1、3-2 則一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 3-1 下载预训练模型\n",
    "if training_mode == training_modes[0]:\n",
    "    !git clone https://huggingface.co/OedoSoldier/Bert-VITS2-2.3 data/{data_dir}/models\n",
    "elif training_mode == training_modes[1]:\n",
    "    !git clone https://huggingface.co/v3ucn/Bert-vits2-Extra-Pretrained_models data/{data_dir}/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 4 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n",
    "%reload_ext tensorboard\n",
    "model_dir = f\"./data/{data_dir}/models\"\n",
    "%tensorboard --logdir $model_dir\n",
    "\n",
    "!torchrun --nproc_per_node=1 train_ms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP 5 开始推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title STEP 5 推理测试\n",
    "#@markdown #STEP 5\n",
    "#@markdown ##推理测试\n",
    "\n",
    "#@markdown ###\n",
    "#@markdown ###推理所使用的模型步數\n",
    "model_step = 2000 # @param {type:\"integer\"}\n",
    "import yaml\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data\n",
    "def save_yaml(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)\n",
    "# 載入 YAML 檔案\n",
    "yaml_file_path = 'config.yml'\n",
    "yaml_data = load_yaml(yaml_file_path)\n",
    "# 修改 YAML 中的內容\n",
    "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
    "yaml_data['webui']['share'] = \"true\"\n",
    "yaml_data['webui']['model'] = f\"models/G_{model_step}.pth\"\n",
    "yaml_data['webui']['config_path'] = \"configs/config.json\"\n",
    "# 儲存修改後的 YAML 檔案\n",
    "save_yaml(yaml_data, yaml_file_path)\n",
    "!torchrun --nproc_per_node=1 webui.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
